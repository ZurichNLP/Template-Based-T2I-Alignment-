{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"API key not loaded. Please check your .env file.\")\n",
    "else:\n",
    "    print(f\"API key loaded: {api_key[:5]}...\")  # Partial display for security\n",
    "\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"Say hello!\"}]\n",
    "    )\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(\"Error during API call:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import asyncio\n",
    "import random  # Added this import\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "from openai import OpenAI\n",
    "from rich.console import Console\n",
    "from rich.progress import Progress, SpinnerColumn, TimeElapsedColumn\n",
    "from functools import partial\n",
    "\n",
    "# Keep the same styles dictionary from original code\n",
    "STYLES = {\n",
    "    \"Cartoon\": \"Simple forms with clear outlines and flat colors, ideal for cognitive processing and bounding box annotation\",\n",
    "    \"Realistic\": \"Natural representations with clear object separation and recognizable elements for real-world connection\",\n",
    "    \"Artistic\": \"Stylized interpretation with distinct elements and good spacing for visual clarity\",\n",
    "    \"Minimalistic\": \"Essential elements only with high contrast and clear object boundaries for reduced cognitive load\",\n",
    "    \"Digital Art\": \"Clean rendering with sharp edges and distinct object separation for clear visual hierarchy\",\n",
    "    \"3D Rendered\": \"Moderate depth with clear object boundaries and minimal overlap for spatial understanding\",\n",
    "    \"Geometric\": \"Basic shapes with clear spacing and easy-to-mark boundaries for simplified processing\",\n",
    "    \"Retro\": \"Simplified vintage style with bold shapes and clear figure-ground separation for visual distinction\",\n",
    "    \"Storybook\": \"Simple but engaging style with clear object definition and comfortable viewing for enhanced comprehension\",\n",
    "    \"Technical\": \"Precise linework with systematic layout and well-defined components for structured understanding\"\n",
    "}\n",
    "\n",
    "# Refined template focusing on strengths of Basic Object Focus\n",
    "REFINED_TEMPLATE = {\n",
    "    \"Basic Object Focus\": {\n",
    "        \"description\": \"Enhanced single-plane arrangement optimizing object clarity and cognitive accessibility\",\n",
    "        \"requirements\": [\n",
    "            \"Place exactly 4 distinct objects (optimal for cognitive processing)\",\n",
    "            \"Maintain 30% minimum spacing between objects (increased from original)\",\n",
    "            \"Use solid-colored neutral background (preferably light gray)\",\n",
    "            \"Ensure maximum contrast between objects\",\n",
    "            \"Position objects in a simple horizontal arrangement\",\n",
    "            \"Scale objects to similar sizes (within 10% variation)\",\n",
    "            \"Avoid any shadows or lighting effects that might create confusion\",\n",
    "            \"Keep object details clear but minimal\"\n",
    "        ],\n",
    "        \"cognitive_benefits\": \"Maximizes cognitive accessibility through optimal object count, enhanced spacing, and clear visual hierarchy\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Keep the original system prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert at creating accessible image generation prompts for a research project on cognitive accessibility.\n",
    "\n",
    "RESEARCH CONTEXT:\n",
    "- Target Audience: People with cognitive disabilities and reading difficulties\n",
    "- Primary Goal: Enhance text comprehension through accessible multimodal content\n",
    "- Research Setting: Master's thesis investigating multimodal accessibility\n",
    "- Validation Process: Images will be annotated by students using Label Studio\n",
    "\n",
    "MANDATORY REQUIREMENTS FOR ALL PROMPTS:\n",
    "1. Objects and Layout:\n",
    "   - Include EXACTLY 4 distinct physical objects\n",
    "   - Maintain 30% minimum spacing between objects\n",
    "   - No overlapping elements\n",
    "   - Clear boundaries between objects\n",
    "\n",
    "2. Content Restrictions:\n",
    "   - NO text or writing elements\n",
    "   - NO dynamic actions or motion\n",
    "   - NO abstract concepts\n",
    "   - NO complex backgrounds\"\"\"\n",
    "\n",
    "class RefinedPromptGenerator:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.console = Console()\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.output_path = os.path.join('..', 'output_files', 'refined_prompts.json')\n",
    "        \n",
    "    async def generate_refined_prompt(self, text: str) -> Dict:\n",
    "        \"\"\"Generate refined prompt using the enhanced Basic Object Focus template.\"\"\"\n",
    "        try:\n",
    "            template_info = REFINED_TEMPLATE[\"Basic Object Focus\"]\n",
    "            \n",
    "            user_prompt = f'''Given this simplified text: \"{text}\"\n",
    "\n",
    "Create a prompt optimized for cognitive accessibility using these enhanced requirements:\n",
    "\n",
    "Template Description: {template_info['description']}\n",
    "\n",
    "Enhanced Requirements:\n",
    "{chr(10).join(f\"- {req}\" for req in template_info['requirements'])}\n",
    "\n",
    "Available styles: {\", \".join(STYLES.keys())}\n",
    "\n",
    "Format as:\n",
    "style: [pick one style]\n",
    "prompt: [your prompt]'''\n",
    "\n",
    "            response = await asyncio.get_event_loop().run_in_executor(\n",
    "                None,\n",
    "                partial(\n",
    "                    self.client.chat.completions.create,\n",
    "                    model=\"gpt-4\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": user_prompt}\n",
    "                    ],\n",
    "                    temperature=0.7\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            content = response.choices[0].message.content.strip()\n",
    "            style = content.split('style:', 1)[1].split('\\n', 1)[0].strip()\n",
    "            prompt = content.split('prompt:', 1)[1].strip()\n",
    "            \n",
    "            if style in STYLES:\n",
    "                return {\n",
    "                    'style': style,\n",
    "                    'prompt': prompt,\n",
    "                    'template_name': \"Basic Object Focus (Refined)\"\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.console.print(f\"[yellow]Error generating prompt: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    async def process_single_sample(self, sample: Dict, index: int) -> Dict:\n",
    "        \"\"\"Process a single sample.\"\"\"\n",
    "        prompt_result = await self.generate_refined_prompt(sample['simplified'])\n",
    "        \n",
    "        if prompt_result:\n",
    "            return {\n",
    "                'index': index,\n",
    "                'id': sample['id'],\n",
    "                'simplified_text': sample['simplified'],\n",
    "                'template_prompts': [prompt_result]\n",
    "            }\n",
    "        return None\n",
    "\n",
    "    def save_results(self, results: List[Dict]):\n",
    "        \"\"\"Save results to file.\"\"\"\n",
    "        os.makedirs(os.path.dirname(self.output_path), exist_ok=True)\n",
    "        with open(self.output_path, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "\n",
    "    async def process_samples(self):\n",
    "        \"\"\"Process 20 samples (5 from each dataset) with enhanced error handling and progress tracking.\"\"\"\n",
    "        input_path = os.path.join('..', 'output_files', 'complete_dataset.json')\n",
    "        \n",
    "        try:\n",
    "            # Check if file exists\n",
    "            if not os.path.exists(input_path):\n",
    "                self.console.print(f\"[red]Error: Input file not found at {input_path}\")\n",
    "                return\n",
    "\n",
    "            # Updated dataset names to match your JSON file\n",
    "            dataset_samples = {\n",
    "                'SimPA': [],\n",
    "                'ASSET': [],\n",
    "                'Wikipedia': [],\n",
    "                'OneStopEnglish': []\n",
    "            }\n",
    "            \n",
    "            # Read and categorize samples by dataset\n",
    "            try:\n",
    "                with open(input_path, 'r') as f:\n",
    "                    line_count = 0\n",
    "                    valid_samples = 0\n",
    "                    for line in f:\n",
    "                        line_count += 1\n",
    "                        try:\n",
    "                            sample = json.loads(line.strip())\n",
    "                            dataset = sample.get('dataset', '')\n",
    "                            if dataset in dataset_samples:\n",
    "                                dataset_samples[dataset].append(sample)\n",
    "                                valid_samples += 1\n",
    "                            else:\n",
    "                                self.console.print(f\"[yellow]Warning: Unknown dataset '{dataset}' in line {line_count}\")\n",
    "                        except json.JSONDecodeError as e:\n",
    "                            self.console.print(f\"[yellow]Warning: Invalid JSON at line {line_count}: {str(e)}\")\n",
    "\n",
    "                    self.console.print(f\"[blue]Processed {line_count} lines, found {valid_samples} valid samples\")\n",
    "                    \n",
    "                    # Print initial dataset distribution\n",
    "                    self.console.print(\"\\n[blue]Initial dataset distribution:\")\n",
    "                    for dataset, samples in dataset_samples.items():\n",
    "                        self.console.print(f\"{dataset}: {len(samples)} samples\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                self.console.print(f\"[red]Error reading file: {str(e)}\")\n",
    "                return\n",
    "\n",
    "            # Sample 5 from each dataset\n",
    "            target_samples = []\n",
    "            for dataset, dataset_data in dataset_samples.items():\n",
    "                sample_size = min(5, len(dataset_data))\n",
    "                if sample_size == 0:\n",
    "                    self.console.print(f\"[yellow]Warning: No samples found for {dataset}\")\n",
    "                else:\n",
    "                    selected = random.sample(dataset_data, sample_size)\n",
    "                    target_samples.extend(selected)\n",
    "                    self.console.print(f\"Selected {len(selected)} samples from {dataset}\")\n",
    "\n",
    "            if not target_samples:\n",
    "                self.console.print(\"[red]Error: No valid samples to process\")\n",
    "                return\n",
    "\n",
    "            # Process samples with rate limiting\n",
    "            all_results = []\n",
    "            with Progress(\n",
    "                SpinnerColumn(),\n",
    "                *Progress.get_default_columns(),\n",
    "                TimeElapsedColumn(),\n",
    "                console=self.console\n",
    "            ) as progress:\n",
    "                task = progress.add_task(\"Processing samples...\", total=len(target_samples))\n",
    "                \n",
    "                # Process samples with rate limiting\n",
    "                semaphore = asyncio.Semaphore(3)  # Limit concurrent API calls\n",
    "                \n",
    "                async def process_with_rate_limit(sample, index):\n",
    "                    async with semaphore:\n",
    "                        result = await self.process_single_sample(sample, index)\n",
    "                        if result:\n",
    "                            result['dataset_source'] = sample.get('dataset', 'unknown')\n",
    "                        return result\n",
    "                \n",
    "                tasks = [process_with_rate_limit(sample, i) \n",
    "                        for i, sample in enumerate(target_samples)]\n",
    "                \n",
    "                for coro in asyncio.as_completed(tasks):\n",
    "                    result = await coro\n",
    "                    if result:\n",
    "                        all_results.append(result)\n",
    "                        progress.update(task, advance=1)\n",
    "                        \n",
    "                        # Save intermediate results every 5 samples\n",
    "                        if len(all_results) % 5 == 0:\n",
    "                            self.save_results(all_results)\n",
    "                            dataset_counts = {}\n",
    "                            for r in all_results:\n",
    "                                ds = r.get('dataset_source', 'unknown')\n",
    "                                dataset_counts[ds] = dataset_counts.get(ds, 0) + 1\n",
    "                            self.console.print(\"\\nCurrent dataset distribution:\")\n",
    "                            for ds, count in dataset_counts.items():\n",
    "                                self.console.print(f\"{ds}: {count} samples\")\n",
    "            \n",
    "            # Final save\n",
    "            self.save_results(all_results)\n",
    "            \n",
    "            # Print final distribution\n",
    "            dataset_counts = {}\n",
    "            for r in all_results:\n",
    "                ds = r.get('dataset_source', 'unknown')\n",
    "                dataset_counts[ds] = dataset_counts.get(ds, 0) + 1\n",
    "            \n",
    "            self.console.print(\"\\n[green]Final dataset distribution:\")\n",
    "            for ds, count in dataset_counts.items():\n",
    "                self.console.print(f\"{ds}: {count} samples\")\n",
    "            \n",
    "            self.console.print(f\"\\n[green]Successfully processed {len(all_results)} samples!\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.console.print(f\"[red]Error: {str(e)}\")\n",
    "def run_async_code():\n",
    "    \"\"\"Helper function to run async code in both script and notebook environments\"\"\"\n",
    "    try:\n",
    "        # Get API key\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY environment variable not set\")\n",
    "        \n",
    "        # Initialize generator\n",
    "        generator = RefinedPromptGenerator(api_key)\n",
    "        \n",
    "        # Try to get the current event loop\n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "        except RuntimeError:\n",
    "            loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(loop)\n",
    "        \n",
    "        # If we're in a notebook with a running event loop\n",
    "        if loop.is_running():\n",
    "            asyncio.ensure_future(generator.process_samples())\n",
    "        else:\n",
    "            # We're either in a script or notebook without running loop\n",
    "            loop.run_until_complete(generator.process_samples())\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in execution: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_async_code()\n",
    "else:\n",
    "    # We're in a notebook or being imported as a module\n",
    "    run_async_code()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
