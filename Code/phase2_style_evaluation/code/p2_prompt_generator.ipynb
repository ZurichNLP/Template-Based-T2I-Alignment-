{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rich'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrich\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconsole\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Console\n\u001b[0;32m      4\u001b[0m console \u001b[38;5;241m=\u001b[39m Console()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Count samples in input file\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rich'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Count samples in input file\n",
    "try:\n",
    "    with open('complete_dataset_400.json', 'r') as f:\n",
    "        input_samples = [json.loads(line) for line in f]\n",
    "    console.print(f\"\\n[blue]Input file contains {len(input_samples)} samples[/blue]\")\n",
    "\n",
    "    # Count unique dataset sources\n",
    "    dataset_counts = {}\n",
    "    for sample in input_samples:\n",
    "        dataset = sample.get('dataset', 'unknown')\n",
    "        dataset_counts[dataset] = dataset_counts.get(dataset, 0) + 1\n",
    "\n",
    "    console.print(\"\\n[green]Samples per dataset:[/green]\")\n",
    "    for dataset, count in sorted(dataset_counts.items()):\n",
    "        console.print(f\"{dataset}: {count} samples\")\n",
    "        \n",
    "    # Check if generated prompts file exists\n",
    "    try:\n",
    "        with open('refined_prompts.json', 'r') as f:\n",
    "            generated_samples = json.load(f)\n",
    "        console.print(f\"\\n[blue]Generated prompts file contains {len(generated_samples)} samples[/blue]\")\n",
    "        \n",
    "        # Compare numbers\n",
    "        if len(input_samples) != len(generated_samples):\n",
    "            console.print(f\"\\n[red]Mismatch detected:[/red]\")\n",
    "            console.print(f\"Input samples: {len(input_samples)}\")\n",
    "            console.print(f\"Generated samples: {len(generated_samples)}\")\n",
    "            console.print(f\"Difference: {len(input_samples) - len(generated_samples)} samples missing\")\n",
    "    except FileNotFoundError:\n",
    "        console.print(\"\\n[yellow]No generated prompts file found[/yellow]\")\n",
    "    except json.JSONDecodeError:\n",
    "        console.print(\"\\n[red]Error reading generated prompts file - it might be corrupted[/red]\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    console.print(\"\\n[red]Input file 'complete_dataset_400.json' not found[/red]\")\n",
    "except json.JSONDecodeError:\n",
    "    console.print(\"\\n[red]Error reading input file - it might be corrupted[/red]\")\n",
    "except Exception as e:\n",
    "    console.print(f\"\\n[red]Unexpected error: {str(e)}[/red]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load .env file\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"API key not loaded. Please check your .env file.\")\n",
    "else:\n",
    "    print(f\"API key loaded: {api_key[:5]}...\")  # Partial display for security\n",
    "\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"Say hello!\"}]\n",
    "    )\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(\"Error during API call:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">Processing </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">400</span><span style=\"color: #000080; text-decoration-color: #000080\"> remaining samples...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mProcessing \u001b[0m\u001b[1;34m400\u001b[0m\u001b[34m remaining samples\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\SouayedBelkiss\\OneDrive - gae\\Desktop\\Thesis\\thesis\\Lib\\site-packages\\rich\\live.py:231: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\SouayedBelkiss\\OneDrive - gae\\Desktop\\Thesis\\thesis\\Lib\\site-packages\\rich\\live.py:231: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import asyncio\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "from openai import OpenAI\n",
    "from rich.console import Console\n",
    "from rich.progress import Progress, SpinnerColumn, TimeElapsedColumn\n",
    "from functools import partial\n",
    "\n",
    "# File paths\n",
    "INPUT_PATH = 'complete_dataset_400.json'\n",
    "OUTPUT_PATH = 'refined_prompts.json'\n",
    "PROGRESS_FILE = 'generation_progress.json'\n",
    "\n",
    "# System prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert at creating accessible image generation prompts for a research project on cognitive accessibility.\n",
    "\n",
    "RESEARCH CONTEXT:\n",
    "- Target Audience: People with cognitive disabilities and reading difficulties\n",
    "- Primary Goal: Enhance text comprehension through accessible multimodal content\n",
    "- Validation Process: Images will be annotated by students using Label Studio\n",
    "\n",
    "MANDATORY REQUIREMENTS FOR ALL PROMPTS:\n",
    "1. Objects and Layout:\n",
    "   - Include 3-5 distinct physical objects (optimal: 4)\n",
    "   - Maintain 30% minimum spacing between objects\n",
    "   - No overlapping elements\n",
    "   - Clear boundaries between objects\n",
    "\n",
    "2. Content Restrictions:\n",
    "   - NO text or writing elements\n",
    "   - NO dynamic actions or motion\n",
    "   - NO abstract concepts\n",
    "   - NO complex backgrounds\"\"\"\n",
    "\n",
    "# Styles dictionary\n",
    "STYLES = {\n",
    "    \"Cartoon\": \"Simple forms with clear outlines and flat colors, ideal for cognitive processing and bounding box annotation\",\n",
    "    \"Realistic\": \"Natural representations with clear object separation and recognizable elements for real-world connection\",\n",
    "    \"Artistic\": \"Stylized interpretation with distinct elements and good spacing for visual clarity\",\n",
    "    \"Minimalistic\": \"Essential elements only with high contrast and clear object boundaries for reduced cognitive load\",\n",
    "    \"Digital Art\": \"Clean rendering with sharp edges and distinct object separation for clear visual hierarchy\",\n",
    "    \"3D Rendered\": \"Moderate depth with clear object boundaries and minimal overlap for spatial understanding\",\n",
    "    \"Geometric\": \"Basic shapes with clear spacing and easy-to-mark boundaries for simplified processing\",\n",
    "    \"Retro\": \"Simplified vintage style with bold shapes and clear figure-ground separation for visual distinction\",\n",
    "    \"Storybook\": \"Simple but engaging style with clear object definition and comfortable viewing for enhanced comprehension\",\n",
    "    \"Technical\": \"Precise linework with systematic layout and well-defined components for structured understanding\"\n",
    "}\n",
    "\n",
    "# Template\n",
    "REFINED_TEMPLATE = {\n",
    "    \"Basic Object Focus\": {\n",
    "        \"description\": \"Enhanced single-plane arrangement optimizing object clarity and cognitive accessibility\",\n",
    "        \"requirements\": [\n",
    "            \"Place exactly 4 distinct objects (optimal for cognitive processing)\",\n",
    "            \"Maintain 30% minimum spacing between objects (increased from original)\",\n",
    "            \"Use solid-colored neutral background (preferably light gray)\",\n",
    "            \"Ensure maximum contrast between objects\",\n",
    "            \"Position objects in a simple horizontal arrangement\",\n",
    "            \"Scale objects to similar sizes (within 10% variation)\",\n",
    "            \"Avoid any shadows or lighting effects that might create confusion\",\n",
    "            \"Keep object details clear but minimal\"\n",
    "        ],\n",
    "        \"cognitive_benefits\": \"Maximizes cognitive accessibility through optimal object count, enhanced spacing, and clear visual hierarchy\"\n",
    "    }\n",
    "}\n",
    "\n",
    "class RefinedPromptGenerator:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.console = Console()\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.output_path = OUTPUT_PATH\n",
    "        self.processed_ids = self.load_progress()\n",
    "\n",
    "    def load_progress(self) -> set:\n",
    "        \"\"\"Load IDs of already processed samples.\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(PROGRESS_FILE):\n",
    "                with open(PROGRESS_FILE, 'r') as f:\n",
    "                    progress_data = json.load(f)\n",
    "                    return set(progress_data.get('processed_ids', []))\n",
    "            return set()\n",
    "        except Exception as e:\n",
    "            self.console.print(f\"[yellow]Error loading progress: {str(e)}\")\n",
    "            return set()\n",
    "\n",
    "    def save_progress(self):\n",
    "        \"\"\"Save progress of processed sample IDs.\"\"\"\n",
    "        try:\n",
    "            with open(PROGRESS_FILE, 'w') as f:\n",
    "                json.dump({'processed_ids': list(self.processed_ids)}, f)\n",
    "        except Exception as e:\n",
    "            self.console.print(f\"[yellow]Error saving progress: {str(e)}\")\n",
    "\n",
    "    async def generate_style_variation(self, text: str, style: str) -> Dict:\n",
    "        \"\"\"Generate a prompt for a specific style using the Basic Object Focus template.\"\"\"\n",
    "        try:\n",
    "            template_info = REFINED_TEMPLATE[\"Basic Object Focus\"]\n",
    "            \n",
    "            user_prompt = f'''Given this simplified text: \"{text}\"\n",
    "\n",
    "Create a prompt optimized for cognitive accessibility in {style} style using these requirements:\n",
    "\n",
    "Template Description: {template_info['description']}\n",
    "\n",
    "Enhanced Requirements:\n",
    "{chr(10).join(f\"- {req}\" for req in template_info['requirements'])}\n",
    "\n",
    "Maintain the style characteristics of {style}: {STYLES[style]}'''\n",
    "\n",
    "            response = await asyncio.get_event_loop().run_in_executor(\n",
    "                None,\n",
    "                partial(\n",
    "                    self.client.chat.completions.create,\n",
    "                    model=\"gpt-4\", \n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": user_prompt}\n",
    "                    ],\n",
    "                    temperature=0.7\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            prompt = response.choices[0].message.content.strip()\n",
    "            \n",
    "            return {\n",
    "                'style': style,\n",
    "                'prompt': prompt,\n",
    "                'template_name': \"Basic Object Focus (Refined)\"\n",
    "            }\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.console.print(f\"[yellow]Error generating prompt for style {style}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    async def process_single_sample(self, sample: Dict, index: int) -> Dict:\n",
    "        \"\"\"Process a single sample with style variations.\"\"\"\n",
    "        if sample['id'] in self.processed_ids:\n",
    "            self.console.print(f\"[blue]Skipping already processed sample {sample['id']}\")\n",
    "            return None\n",
    "\n",
    "        all_style_prompts = []\n",
    "        selected_styles = list(STYLES.keys())\n",
    "        \n",
    "        for style in selected_styles:\n",
    "            prompt_result = await self.generate_style_variation(sample['simplified'], style)\n",
    "            if prompt_result:\n",
    "                all_style_prompts.append(prompt_result)\n",
    "\n",
    "        if all_style_prompts:\n",
    "            self.processed_ids.add(sample['id'])\n",
    "            self.save_progress()\n",
    "            \n",
    "            return {\n",
    "                'index': index,\n",
    "                'id': sample['id'],\n",
    "                'simplified_text': sample['simplified'],\n",
    "                'dataset_source': sample.get('dataset', 'unknown'),\n",
    "                'template_prompts': all_style_prompts\n",
    "            }\n",
    "        return None\n",
    "\n",
    "    async def process_samples(self):\n",
    "        \"\"\"Process remaining unprocessed samples.\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(INPUT_PATH):\n",
    "                self.console.print(f\"[red]Error: Input file not found at {INPUT_PATH}\")\n",
    "                return\n",
    "\n",
    "            # Load existing results\n",
    "            existing_results = []\n",
    "            if os.path.exists(OUTPUT_PATH):\n",
    "                try:\n",
    "                    with open(OUTPUT_PATH, 'r') as f:\n",
    "                        existing_results = json.load(f)\n",
    "                except json.JSONDecodeError:\n",
    "                    self.console.print(\"[yellow]Warning: Could not load existing results, starting fresh\")\n",
    "\n",
    "            # Load samples from 400 dataset\n",
    "            with open(INPUT_PATH, 'r') as f:\n",
    "                samples = [json.loads(line) for line in f]\n",
    "\n",
    "            # Filter out already processed samples\n",
    "            unprocessed_samples = [s for s in samples if s['id'] not in self.processed_ids]\n",
    "            \n",
    "            if not unprocessed_samples:\n",
    "                self.console.print(\"[green]All samples have been processed!\")\n",
    "                return\n",
    "\n",
    "            self.console.print(f\"[blue]Processing {len(unprocessed_samples)} remaining samples...\")\n",
    "\n",
    "            # Process samples\n",
    "            with Progress(\n",
    "                SpinnerColumn(),\n",
    "                *Progress.get_default_columns(),\n",
    "                TimeElapsedColumn(),\n",
    "                console=self.console\n",
    "            ) as progress:\n",
    "                task = progress.add_task(\"Processing samples...\", total=len(unprocessed_samples))\n",
    "                \n",
    "                semaphore = asyncio.Semaphore(3)\n",
    "                \n",
    "                async def process_with_rate_limit(sample, index):\n",
    "                    async with semaphore:\n",
    "                        return await self.process_single_sample(sample, index)\n",
    "                \n",
    "                tasks = [process_with_rate_limit(sample, i) \n",
    "                        for i, sample in enumerate(unprocessed_samples)]\n",
    "                \n",
    "                new_results = []\n",
    "                for coro in asyncio.as_completed(tasks):\n",
    "                    result = await coro\n",
    "                    if result:\n",
    "                        new_results.append(result)\n",
    "                        progress.update(task, advance=1)\n",
    "                        \n",
    "                        # Save progress every 5 samples\n",
    "                        if len(new_results) % 5 == 0:\n",
    "                            all_results = existing_results + new_results\n",
    "                            self.save_results(all_results)\n",
    "                            self._print_progress_stats(all_results)\n",
    "\n",
    "            # Final save\n",
    "            all_results = existing_results + new_results\n",
    "            self.save_results(all_results)\n",
    "            self._print_progress_stats(all_results)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.console.print(f\"[red]Error: {str(e)}\")\n",
    "\n",
    "    def _print_progress_stats(self, results: List[Dict]):\n",
    "        \"\"\"Print current progress statistics.\"\"\"\n",
    "        dataset_counts = {}\n",
    "        style_counts = {}\n",
    "        \n",
    "        for result in results:\n",
    "            ds = result.get('dataset_source', 'unknown')\n",
    "            dataset_counts[ds] = dataset_counts.get(ds, 0) + 1\n",
    "            \n",
    "            for prompt in result.get('template_prompts', []):\n",
    "                style = prompt.get('style', 'unknown')\n",
    "                style_counts[style] = style_counts.get(style, 0) + 1\n",
    "\n",
    "        self.console.print(\"\\n[blue]Current progress:\")\n",
    "        self.console.print(\"\\nDataset distribution:\")\n",
    "        for ds, count in dataset_counts.items():\n",
    "            self.console.print(f\"{ds}: {count} samples\")\n",
    "        \n",
    "        self.console.print(\"\\nStyle distribution:\")\n",
    "        for style, count in style_counts.items():\n",
    "            self.console.print(f\"{style}: {count} prompts\")\n",
    "\n",
    "    def save_results(self, results: List[Dict]):\n",
    "        \"\"\"Save results to file.\"\"\"\n",
    "        with open(self.output_path, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "\n",
    "# Create a new cell with this code to run\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable not set\")\n",
    "\n",
    "generator = RefinedPromptGenerator(api_key)\n",
    "\n",
    "try:\n",
    "    loop = asyncio.get_event_loop()\n",
    "except RuntimeError:\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "\n",
    "if loop.is_running():\n",
    "    asyncio.ensure_future(generator.process_samples())\n",
    "else:\n",
    "    loop.run_until_complete(generator.process_samples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Prompt Generation Validation Report</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mPrompt Generation Validation Report\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Total samples processed: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Total samples processed: \u001b[1;36m400\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">         Style Distribution          </span>\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Style        </span>┃<span style=\"font-weight: bold\"> Count </span>┃<span style=\"font-weight: bold\"> Coverage % </span>┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> 3D Rendered  </span>│<span style=\"color: #008000; text-decoration-color: #008000\">   400 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">    100.00% </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Artistic     </span>│<span style=\"color: #008000; text-decoration-color: #008000\">   400 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">    100.00% </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Cartoon      </span>│<span style=\"color: #008000; text-decoration-color: #008000\">   400 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">    100.00% </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Digital Art  </span>│<span style=\"color: #008000; text-decoration-color: #008000\">   400 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">    100.00% </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Geometric    </span>│<span style=\"color: #008000; text-decoration-color: #008000\">   400 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">    100.00% </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Minimalistic </span>│<span style=\"color: #008000; text-decoration-color: #008000\">   400 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">    100.00% </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Realistic    </span>│<span style=\"color: #008000; text-decoration-color: #008000\">   400 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">    100.00% </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Retro        </span>│<span style=\"color: #008000; text-decoration-color: #008000\">   400 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">    100.00% </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Storybook    </span>│<span style=\"color: #008000; text-decoration-color: #008000\">   400 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">    100.00% </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Technical    </span>│<span style=\"color: #008000; text-decoration-color: #008000\">   400 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">    100.00% </span>│\n",
       "└──────────────┴───────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m         Style Distribution          \u001b[0m\n",
       "┏━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mStyle       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCount\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCoverage %\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m3D Rendered \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m  400\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m   100.00%\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mArtistic    \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m  400\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m   100.00%\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mCartoon     \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m  400\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m   100.00%\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mDigital Art \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m  400\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m   100.00%\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mGeometric   \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m  400\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m   100.00%\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mMinimalistic\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m  400\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m   100.00%\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mRealistic   \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m  400\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m   100.00%\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mRetro       \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m  400\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m   100.00%\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mStorybook   \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m  400\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m   100.00%\u001b[0m\u001b[33m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTechnical   \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m  400\u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m   100.00%\u001b[0m\u001b[33m \u001b[0m│\n",
       "└──────────────┴───────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ All samples have all </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">10</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> styles!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32m✓ All samples have all \u001b[0m\u001b[1;32m10\u001b[0m\u001b[1;32m styles!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Additional Statistics:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mAdditional Statistics:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Average styles per sample: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Average styles per sample: \u001b[1;36m10.00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Samples with all <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> styles: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.00</span>%<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Samples with all \u001b[1;36m10\u001b[0m styles: \u001b[1;36m400\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m100.00\u001b[0m%\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "# Initialize console for pretty printing\n",
    "console = Console()\n",
    "\n",
    "# Load the generated prompts\n",
    "with open('refined_prompts.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize counters\n",
    "total_samples = len(data)\n",
    "style_counts = defaultdict(int)\n",
    "samples_with_missing_styles = []\n",
    "style_distribution = defaultdict(list)\n",
    "\n",
    "# Expected styles\n",
    "expected_styles = set([\n",
    "    \"Cartoon\", \"Realistic\", \"Artistic\", \"Minimalistic\", \"Digital Art\",\n",
    "    \"3D Rendered\", \"Geometric\", \"Retro\", \"Storybook\", \"Technical\"\n",
    "])\n",
    "\n",
    "# Analyze each sample\n",
    "for sample in data:\n",
    "    sample_id = sample['id']\n",
    "    prompts = sample.get('template_prompts', [])\n",
    "    styles_in_sample = set()\n",
    "    \n",
    "    for prompt in prompts:\n",
    "        style = prompt.get('style')\n",
    "        if style:\n",
    "            style_counts[style] += 1\n",
    "            styles_in_sample.add(style)\n",
    "            style_distribution[style].append(sample_id)\n",
    "    \n",
    "    if len(styles_in_sample) != 10:\n",
    "        samples_with_missing_styles.append({\n",
    "            'id': sample_id,\n",
    "            'found_styles': len(styles_in_sample),\n",
    "            'missing_styles': expected_styles - styles_in_sample\n",
    "        })\n",
    "\n",
    "# Create validation report\n",
    "console.print(\"\\n[bold blue]Prompt Generation Validation Report[/bold blue]\")\n",
    "console.print(f\"\\nTotal samples processed: {total_samples}\")\n",
    "\n",
    "# Create style distribution table\n",
    "table = Table(title=\"Style Distribution\")\n",
    "table.add_column(\"Style\", style=\"cyan\")\n",
    "table.add_column(\"Count\", justify=\"right\", style=\"green\")\n",
    "table.add_column(\"Coverage %\", justify=\"right\", style=\"yellow\")\n",
    "\n",
    "for style in sorted(style_counts.keys()):\n",
    "    count = style_counts[style]\n",
    "    coverage = (count / total_samples) * 100\n",
    "    table.add_row(\n",
    "        style,\n",
    "        str(count),\n",
    "        f\"{coverage:.2f}%\"\n",
    "    )\n",
    "\n",
    "console.print(table)\n",
    "\n",
    "# Report on samples with missing styles\n",
    "if samples_with_missing_styles:\n",
    "    console.print(\"\\n[bold red]Samples with Missing Styles:[/bold red]\")\n",
    "    for sample in samples_with_missing_styles:\n",
    "        console.print(f\"\\nSample ID: {sample['id']}\")\n",
    "        console.print(f\"Found {sample['found_styles']} styles\")\n",
    "        console.print(\"Missing styles:\", \", \".join(sorted(sample['missing_styles'])))\n",
    "\n",
    "    console.print(f\"\\nTotal samples with missing styles: {len(samples_with_missing_styles)}\")\n",
    "else:\n",
    "    console.print(\"\\n[bold green]✓ All samples have all 10 styles![/bold green]\")\n",
    "\n",
    "# Additional statistics\n",
    "console.print(\"\\n[bold blue]Additional Statistics:[/bold blue]\")\n",
    "console.print(f\"Average styles per sample: {sum(style_counts.values()) / total_samples:.2f}\")\n",
    "perfect_samples = total_samples - len(samples_with_missing_styles)\n",
    "console.print(f\"Samples with all 10 styles: {perfect_samples} ({(perfect_samples/total_samples)*100:.2f}%)\")\n",
    "\n",
    "# Save problematic samples to file if any exist\n",
    "if samples_with_missing_styles:\n",
    "    with open('missing_styles_report.json', 'w') as f:\n",
    "        json.dump(samples_with_missing_styles, f, indent=2)\n",
    "    console.print(\"\\n[yellow]Detailed report of samples with missing styles saved to 'missing_styles_report.json'[/yellow]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
